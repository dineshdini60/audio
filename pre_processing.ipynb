{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import dct\n",
    "from scipy.signal import savgol_filter\n",
    "from PyEMD import EMD\n",
    "\n",
    "\n",
    "def first_step(sample_rate,signal):\n",
    "    \n",
    "    ##### Pre-Emphasis\n",
    "    #set filter coefficient for pre-emphasis  filter coefficient (Î±) \n",
    "    pre_emphasis = 0.97 #typical value need to be set                                                 **\n",
    "    \n",
    "    emphasized_signal = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "    \n",
    "    ##### sav_gol filter                                                                               **\n",
    "    #link:- https://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.signal.savgol_filter.html\n",
    "    np.set_printoptions(precision=2)  # For compact display.\n",
    "    after_savgol_signal = savgol_filter(emphasized_signal, 5, 2, mode = 'nearest')\n",
    "    # 5 is the window length and 2 is the polynomial degree \n",
    "    \n",
    "    \n",
    "    ##### emd\n",
    "    #link :- https://github.com/laszukdawid/PyEMD\n",
    "    emd = EMD()        #basic emd\n",
    "    imfs = emd(after_savgol_signal)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in imfs:\n",
    "        #### Framing\n",
    "        #Typical frame sizes in speech processing range from 20 ms to 40 ms \n",
    "        #with 50% (+/-10%) overlap between consecutive frames. \n",
    "        #Popular settings are 25 ms for the frame size,  and a 10 ms stride (15 ms overlap), \n",
    "        #link :- https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html\n",
    "        frame_size = 0.025\n",
    "        frame_stride = 0.01\n",
    "        frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  # Convert from seconds to samples\n",
    "        signal_length = len(i)\n",
    "        frame_length = int(round(frame_length))\n",
    "        frame_step = int(round(frame_step))\n",
    "        num_frames = int(numpy.ceil(float(numpy.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
    "\n",
    "        pad_signal_length = num_frames * frame_step + frame_length\n",
    "        z = numpy.zeros((pad_signal_length - signal_length))\n",
    "        pad_signal = numpy.append(i, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "\n",
    "        indices = numpy.tile(numpy.arange(0, frame_length), (num_frames, 1)) + numpy.tile(numpy.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "        frames = pad_signal[indices.astype(numpy.int32, copy=False)]\n",
    "        \n",
    "        \n",
    "        \n",
    "        ######\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
